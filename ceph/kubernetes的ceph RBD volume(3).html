kubernetes的ceph RBD volume(3)： 动态volume的使用(ceph RBD)<br/><br/><div class="article_content tracking-ad" data-dsm="post" data-mod="popu_307" id="article_content">

<p>我实验了一下kubenetes的dynamic volume，基于ceph RDB. 以下是使用步骤：</p>
<p>1. 准备storageclass, 配置ceph rdb的信息， ceph mon的ip, 用户，密码和ceph pool， 之前secret要生成。<br/>
</p>
<p><br/>
</p>
<p>storageclass:</p>
<p>apiVersion: storage.k8s.io/v1beta1</p>
<p>kind: StorageClass</p>
<p>metadata:</p>
<p>02name: kubepool</p>
<p>02annotations:</p>
<p>020202storageclass.beta.kubernetes.io/is-default-class: 'true'</p>
<p>provisioner: kubernetes.io/rbd</p>
<p>parameters:</p>
<p>020202monitors: 10.0.200.11:6789</p>
<p>020202adminId: kube</p>
<p>020202adminSecretName: ceph-secret</p>
<p>020202adminSecretNamespace: default</p>
<p>020202pool: kube</p>
<p>020202userId: kube</p>
<p>020202userSecretName: ceph-secret</p>
<p>022. 准备 persistent volume claim, <br/>
</p>
<p><br/>
</p>
<p>kind: PersistentVolumeClaim</p>
<p>apiVersion: v1</p>
<p>metadata:</p>
<p>02name: ceph-claim-sc</p>
<p>02annotations:</p>
<p>020202volume.beta.kubernetes.io/storage-class: 'kubepool'</p>
<p>spec:</p>
<p>02accessModes:</p>
<p>020202 -ReadWriteOnce</p>
<p>02resources:</p>
<p>020202requests:</p>
<p>0202020202storage: 20Gi</p>
<p>023. 检查kube resource 和 rbd的image. 发现image已经在pool里被创建，并且格式化。缺省是ext4<br/>
</p>
<p>[root@testnew kube]# kubectl getstorageclass</p>
<p>NAME02020202020202020202020202020202 TYPE</p>
<p>kubepool (default)0202 kubernetes.io/rbd0202 </p>
<p>[root@testnew kube]# kubectl get pvc</p>
<p>NAME0202020202020202020202 STATUS020202 VOLUME020202020202020202020202020202020202020202020202020202020202020202020202CAPACITY0202 ACCESSMODES0202 AGE</p>
<p>ceph-claim0202020202 Bound02020202ceph-pv0202020202020202020202020202020202020202020202020202020202020202020202 50Gi020202020202 RWO02020202020202020202 3h</p>
<p>ceph-claim-sc0202 Bound02020202pvc-ac668f99-3b8b-11e7-8af9-fa163e01317b0202 20Gi020202020202RWO02020202020202020202 7m</p>
<p>[root@testnew kube]# kubectl get pv</p>
<p>NAME0202020202020202020202020202020202020202020202020202020202020202020202020202CAPACITY0202 ACCESSMODES0202 RECLAIMPOLICY0202 STATUS020202CLAIM020202020202020202020202020202020202REASON020202 AGE</p>
<p>ceph-pv0202020202020202020202020202020202020202020202020202020202020202020202 50Gi020202020202 RWO02020202020202020202 Recycle0202020202020202 Bound02020202 default/ceph-claim020202020202020202020202020202 3h</p>
<p>pvc-ac668f99-3b8b-11e7-8af9-fa163e01317b0202 20Gi020202020202RWO02020202020202020202 <span style="color:red">
Delete02 </span>0202020202020202Bound02020202 default/ceph-claim-sc020202020202020202020202 7m</p>
<p>02note: delete reclaimpolicy， 缺省的policy, 意思是pvc被删除，相应的ceph rbd image也将被删除<br/>
</p>
<p>02[root@testnew kube]# rbd -p kube -nclient.kube ls</p>
<p><span style="color:red">kubernetes-dynamic-pvc-ac6b857a-3b8b-11e7-bdfc-fa163e01317b</span></p>
<p>vol1</p>
<p>vol2</p>
<p>vol50</p>
<p><br/>
</p>
<p>4.02 创建rc， 验证是否能够使用volume</p>
<p>apiVersion: v1<br/>
kind: ReplicationController<br/>
metadata:<br/>
02 name: frontendpvcsc<br/>
02 labels:<br/>
020202 name: frontendpvcsc<br/>
spec:<br/>
02 replicas: 1<br/>
02 selector:<br/>
020202 name: frontendpvcsc<br/>
02 template:<br/>
020202 metadata:<br/>
0202020202 labels:<br/>
02020202020202 name: frontendpvcsc<br/>
020202 spec:<br/>
0202020202 containers:<br/>
0202020202 - name: frontendpvcsc<br/>
02020202020202 image: kubeguide/guestbook-php-frontend<br/>
02020202020202 env:<br/>
02020202020202 - name: GET_HOSTS_FROM<br/>
020202020202020202 value: env<br/>
02020202020202 ports:<br/>
02020202020202 - containerPort: 80<br/>
02020202020202 volumeMounts:<br/>
02020202020202 - mountPath: /mnt/rbd<br/>
020202020202020202 name: ceph-vol<br/>
0202020202 volumes:<br/>
0202020202 - name: ceph-vol<br/>
02020202020202 persistentVolumeClaim:<br/>
020202020202020202 claimName: ceph-claim-sc<br/>
<br/>
[root@testnew kube]# kubectl exec frontendpvcsc-xzz15 -it bash<br/>
root@frontendpvcsc-xzz15:/var/www/html# df -h<br/>
Filesystem020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 Size02 Used Avail Use% Mounted on<br/>
/dev/mapper/docker-253:1-528252-1915f387c1f17925e19bbcaa4324e401cc7c1abb5e86a11ee6bddda38f0db1da0202 10G02 609M02 9.4G0202 6% /<br/>
tmpfs0202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 3.9G02020202 002 3.9G0202 0% /dev<br/>
tmpfs0202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 3.9G02020202 002 3.9G0202 0% /sys/fs/cgroup<br/>
/dev/vda10202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 19G02 4.9G0202 14G02 27% /etc/hosts<br/>
<span style="color:#FF0000">/dev/rbd00202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 20G0202 45M0202 19G0202 1% /mnt/rbd</span><br/>
shm0202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202020202 64M02020202 00202 64M0202 0% /dev/shm<br/>
</p>
<p>能够看到volume已经被mount上来了。<br/>
<br/>
总结：</p>
<p>Dynamic volume能够很方便的被用户使用，像一个存储资源池，能动态的分配存储资源。<br/>
</p>
<br/>
   
</div>